{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundational Model Training: MobileNetV4 & MobileNetV5\n",
    "\n",
    "This notebook trains MobileNetV4 and MobileNetV5 models on the processed dataset to serve as foundational models for downstream agricultural vision tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'data_dir': '../data/release',  # Path to the released dataset\n",
    "    'models_to_train': [\n",
    "        'mobilenetv4_conv_medium.e500_r256_in1k', # High performance V4 variant\n",
    "        'mobilenetv5_base.e500_r256_in1k'           # Base V5 variant\n",
    "    ],\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 20,\n",
    "    'learning_rate': 1e-4,\n",
    "    'image_size': 256,\n",
    "    'seed': 42,\n",
    "    'num_workers': 4,\n",
    "    'checkpoint_dir': '../models/foundational'\n",
    "}\n",
    "\n",
    "os.makedirs(CONFIG['checkpoint_dir'], exist_ok=True)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(CONFIG['image_size']),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(int(CONFIG['image_size'] * 1.14)),\n",
    "        transforms.CenterCrop(CONFIG['image_size']),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Data Loading\n",
    "def get_dataloaders(data_dir):\n",
    "    image_datasets = {}\n",
    "    dataloaders = {}\n",
    "    dataset_sizes = {}\n",
    "    class_names = []\n",
    "\n",
    "    for x in ['train', 'val']:\n",
    "        path = os.path.join(data_dir, x)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Warning: {path} not found. Using random split fallback.\")\n",
    "            full_dataset = ImageFolder(data_dir, transform=data_transforms['train'])\n",
    "            train_size = int(0.8 * len(full_dataset))\n",
    "            val_size = len(full_dataset) - train_size\n",
    "            train_dataset, val_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
    "            \n",
    "            val_dataset.dataset.transform = data_transforms['val'] \n",
    "\n",
    "            image_datasets = {'train': train_dataset, 'val': val_dataset}\n",
    "            class_names = full_dataset.classes\n",
    "            break\n",
    "        else:\n",
    "            image_datasets[x] = ImageFolder(path, data_transforms[x])\n",
    "            if x == 'train':\n",
    "                class_names = image_datasets[x].classes\n",
    "\n",
    "    for x in ['train', 'val']:\n",
    "        dataloaders[x] = DataLoader(image_datasets[x], batch_size=CONFIG['batch_size'],\n",
    "                                     shuffle=True if x == 'train' else False, \n",
    "                                     num_workers=CONFIG['num_workers'])\n",
    "        dataset_sizes[x] = len(image_datasets[x])\n",
    "\n",
    "    return dataloaders, dataset_sizes, class_names\n",
    "\n",
    "dataloaders, dataset_sizes, class_names = get_dataloaders(CONFIG['data_dir'])\n",
    "print(f\"Classes: {len(class_names)}\")\n",
    "print(f\"Dataset sizes: {dataset_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, dataloaders, dataset_sizes, num_epochs=25):\n",
    "    print(f\"\nStarting training for {model_name}...\")\n",
    "    \n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=len(class_names))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in tqdm(dataloaders[phase], leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            \n",
    "            history[f'{phase}_loss'].append(epoch_loss)\n",
    "            history[f'{phase}_acc'].append(epoch_acc.item())\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                save_path = os.path.join(CONFIG['checkpoint_dir'], f\"{model_name}_best.pth\")\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                print(f\"New best model saved to {save_path}\")\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute Training\n",
    "for model_name in CONFIG['models_to_train']:\n",
    "    print(f\"=================================================================\")\n",
    "    print(f\"TRAINING MODEL: {model_name}\")\n",
    "    print(f\"=================================================================\")\n",
    "    \n",
    "    clean_name = model_name.split('.')[0]\n",
    "    \n",
    "    trained_model, history = train_model(model_name, dataloaders, dataset_sizes, CONFIG['num_epochs'])\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title(f'{clean_name} Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Acc')\n",
    "    plt.plot(history['val_acc'], label='Val Acc')\n",
    "    plt.legend()\n",
    "    plt.title(f'{clean_name} Accuracy')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    pd.DataFrame(history).to_csv(os.path.join(CONFIG['checkpoint_dir'], f\"{clean_name}_history.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
